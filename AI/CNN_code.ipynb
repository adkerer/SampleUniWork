{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pre-processing\n",
    "Loading data. Splitting csv_data into seen_images and seen_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28000, 785)\n",
      "(28000,)\n",
      "(28000, 28, 28)\n",
      "(14000, 784)\n",
      "(14000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "seen_csv_data = pd.read_csv(\"./nn-assignment/trainset.csv\")\n",
    "#seen data = train data + validation data\n",
    "seen_labels = []\n",
    "seen_images = []\n",
    "print(seen_csv_data.shape)\n",
    "#converting from csv data to (28x28 pixel) image values\n",
    "for row_index in range(0,seen_csv_data.shape[0]):\n",
    "    row = seen_csv_data.iloc[row_index].values\n",
    "    label = row[0]\n",
    "    img = np.reshape(row[1:],newshape=(28,28))\n",
    "    seen_labels.append(label)\n",
    "    seen_images.append(img)\n",
    "\n",
    "seen_labels = np.array(seen_labels)\n",
    "seen_images = np.array(seen_images)\n",
    "print(seen_labels.shape) #shape 28000,1\n",
    "#print(seen_labels[0:30]) \n",
    "print(seen_images.shape)# shape(28000,28,28)\n",
    "\n",
    "#converting from csv data to (28x28 pixel) image values\n",
    "test_csv_data = pd.read_csv(\"./nn-assignment/testset.csv\")\n",
    "test_images = []\n",
    "print(test_csv_data.shape)\n",
    "for row_index in range(0,test_csv_data.shape[0]):\n",
    "    row = test_csv_data.iloc[row_index].values\n",
    "    img = np.reshape(row,newshape=(28,28))\n",
    "    test_images.append(img)\n",
    "\n",
    "test_images = np.array(test_images)\n",
    "print(test_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = test_images.reshape(test_images.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21000, 28, 28)\n",
      "(21000, 28, 28, 1)\n",
      "(14000, 28, 28, 1)\n",
      "(7000, 28, 28, 1) (21000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "#get train/validation split\n",
    "train_percent = 0.75\n",
    "\n",
    "row_len = len(seen_images[:,1])\n",
    "train_len = round(train_percent * row_len)\n",
    "\n",
    "train_index = np.random.choice(row_len,size=train_len, replace=False)\n",
    "#print(len(train_index),train_index[0:50])\n",
    "#print(len(seen_labels[seen_labels[train_index]]))\n",
    "train_images = seen_images[train_index]\n",
    "train_labels = to_categorical(seen_labels[train_index]) \n",
    "print(train_images.shape)\n",
    "train_images = train_images /255 #normalize image values and reshape\n",
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1)\n",
    "print(train_images.shape)\n",
    "#do the same with test data\n",
    "test_images = test_images /255\n",
    "test_images = test_images.reshape(test_images.shape[0], 28, 28, 1)\n",
    "print(test_images.shape)\n",
    "\n",
    "val_index = np.delete(np.array(range(0,len(seen_labels))),train_index)\n",
    "val_images = seen_images[val_index]\n",
    "val_labels = to_categorical(seen_labels[val_index])\n",
    "val_images = val_images.reshape(val_images.shape[0], 28, 28, 1)\n",
    "\n",
    "\n",
    "print(val_images.shape,train_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters = 32, kernel_size= (3,3), strides = (1,1), activation = \"relu\",input_shape = (28,28,1))) #potentially change activation\n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) #pool_size=(2, 2), strides=None, padding=\"valid\", data_format=None, **kwargs\n",
    "model.add(Conv2D(filters = 64,kernel_size = (2,2), strides = (2,2), activation = \"relu\"))\n",
    "model.add(Flatten())#flatten to enable dense layers (flatten in to 1D)\n",
    "model.add(Dense(200,activation=\"relu\"))\n",
    "model.add(Dense(10,activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "657/657 [==============================] - 6s 9ms/step - loss: 0.7342 - accuracy: 0.7570 - val_loss: 32.1678 - val_accuracy: 0.9309\n",
      "Epoch 2/10\n",
      "657/657 [==============================] - 5s 8ms/step - loss: 0.1506 - accuracy: 0.9508 - val_loss: 33.9108 - val_accuracy: 0.9349\n",
      "Epoch 3/10\n",
      "657/657 [==============================] - 5s 8ms/step - loss: 0.0848 - accuracy: 0.9731 - val_loss: 25.4154 - val_accuracy: 0.9557\n",
      "Epoch 4/10\n",
      "657/657 [==============================] - 5s 8ms/step - loss: 0.0552 - accuracy: 0.9816 - val_loss: 34.9309 - val_accuracy: 0.9456\n",
      "Epoch 5/10\n",
      "657/657 [==============================] - 5s 8ms/step - loss: 0.0323 - accuracy: 0.9906 - val_loss: 34.4594 - val_accuracy: 0.9559\n",
      "Epoch 6/10\n",
      "657/657 [==============================] - 5s 8ms/step - loss: 0.0172 - accuracy: 0.9949 - val_loss: 39.8340 - val_accuracy: 0.9557\n",
      "Epoch 7/10\n",
      "657/657 [==============================] - 5s 8ms/step - loss: 0.0133 - accuracy: 0.9957 - val_loss: 49.5876 - val_accuracy: 0.9496\n",
      "Epoch 8/10\n",
      "657/657 [==============================] - 5s 8ms/step - loss: 0.0110 - accuracy: 0.9963 - val_loss: 70.0024 - val_accuracy: 0.9351\n",
      "Epoch 9/10\n",
      "657/657 [==============================] - 5s 8ms/step - loss: 0.0140 - accuracy: 0.9957 - val_loss: 52.4145 - val_accuracy: 0.9541\n",
      "Epoch 10/10\n",
      "657/657 [==============================] - 5s 8ms/step - loss: 0.0076 - accuracy: 0.9982 - val_loss: 56.5828 - val_accuracy: 0.9533\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd550db6310>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images,train_labels,validation_data=(val_images,val_labels),epochs = 10, batch_size=32,verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = model(test_images)\n",
    "#print(predicted_labels.shape)\n",
    "predicted_labels= [np.argmax(row, axis=None, out=None) for row in predicted_labels]\n",
    "output = {\"ImageId\": list(range(1,len(predicted_labels)+1)), \"Label\": predicted_labels }\n",
    "output_df = pd.DataFrame(data=output)\n",
    "#print(output_df.tail())\n",
    "output_df.to_csv(\"predictions.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submitted to a kaggle competition. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
